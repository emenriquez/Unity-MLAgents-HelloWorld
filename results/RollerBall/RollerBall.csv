Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
10000,1.4001727,13.012605042016807,0.51686144,0.5750350631136045,0.5750350631136045,0.12330204,0.24078189,0.00029697927,0.19899309,0.0004950661,1.0
20000,1.3776417,37.59073359073359,0.6133305,0.8957528957528957,0.8957528957528957,0.016547257,0.24238263,0.00029103688,0.19701229,0.00048536027,1.0
30000,1.3639675,10.799528301886792,0.84673935,0.9162735849056604,0.9162735849056604,0.029421022,0.24589999,0.0002850085,0.19500284,0.00047551387,1.0
40000,1.3606468,6.5866983372921615,0.95898724,0.990506329113924,0.990506329113924,0.006385347,0.24488443,0.00027900422,0.1930014,0.00046570686,1.0
50000,1.3632792,7.591584158415841,0.949184,0.9867877786952931,0.9867877786952931,0.010260148,0.23856407,0.00027296823,0.1909894,0.00045584806,1.0
